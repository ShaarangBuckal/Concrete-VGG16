{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "we will be leveraging the ResNet50 model to build our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Adding the ResNet50 pre-trained model to our model. \n",
    "We don't want to include the top layer or the output layer of the pre-trained model. \n",
    "Define our own output layer and train it so that it is optimized for our image dataset. \n",
    "In order to leave out the output layer of the pre-trained model, set the argument *include_top* to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bucka\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 28s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Defining our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x20c14c5ae10>,\n",
       " <keras.layers.core.Dense at 0x20c1bb63198>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The model is composed of two sets of layers. \n",
    "The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Accessing the ResNet50 layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x20c0f7c7978>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x20c796e9860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c796e9898>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c0f7c78d0>,\n",
       " <keras.layers.core.Activation at 0x20c0f7d8c18>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x20c10f8add8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x20c0ddfd0f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11009dd8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c1117b390>,\n",
       " <keras.layers.core.Activation at 0x20c1117bf28>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c1117bfd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c1123fb38>,\n",
       " <keras.layers.core.Activation at 0x20c1123f7b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c112d9cf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c112f8390>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c112f8f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11369630>,\n",
       " <keras.layers.merge.Add at 0x20c113f1eb8>,\n",
       " <keras.layers.core.Activation at 0x20c1148e400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c1144ce10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c114b38d0>,\n",
       " <keras.layers.core.Activation at 0x20c114cd240>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11568400>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11588f28>,\n",
       " <keras.layers.core.Activation at 0x20c11588978>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c115be898>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11615dd8>,\n",
       " <keras.layers.merge.Add at 0x20c1163fba8>,\n",
       " <keras.layers.core.Activation at 0x20c11691fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11691518>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c117385f8>,\n",
       " <keras.layers.core.Activation at 0x20c11738e48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c1176c390>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c117a8b38>,\n",
       " <keras.layers.core.Activation at 0x20c11812f98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11864e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c118cc3c8>,\n",
       " <keras.layers.merge.Add at 0x20c118ec978>,\n",
       " <keras.layers.core.Activation at 0x20c11939470>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c119a2c88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c119c4828>,\n",
       " <keras.layers.core.Activation at 0x20c119def98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11a310b8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11a9c198>,\n",
       " <keras.layers.core.Activation at 0x20c11a9cb00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11b02fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11b90ef0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11af12b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11bc9400>,\n",
       " <keras.layers.merge.Add at 0x20c11c33d68>,\n",
       " <keras.layers.core.Activation at 0x20c11caa048>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11c507b8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11d0e278>,\n",
       " <keras.layers.core.Activation at 0x20c11d2b390>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11dbd518>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11d83fd0>,\n",
       " <keras.layers.core.Activation at 0x20c11de04e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11e9c320>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11ebde80>,\n",
       " <keras.layers.merge.Add at 0x20c11e19d30>,\n",
       " <keras.layers.core.Activation at 0x20c11eefcc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11eefef0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c11f965f8>,\n",
       " <keras.layers.core.Activation at 0x20c11f96470>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c11fca4a8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c1204e940>,\n",
       " <keras.layers.core.Activation at 0x20c12072710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12090ef0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c121482b0>,\n",
       " <keras.layers.merge.Add at 0x20c12148ac8>,\n",
       " <keras.layers.core.Activation at 0x20c1212ae48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c1212a278>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12224438>,\n",
       " <keras.layers.core.Activation at 0x20c12224be0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c1228ca58>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c1226b4e0>,\n",
       " <keras.layers.core.Activation at 0x20c122f7e80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c123169e8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c123b4be0>,\n",
       " <keras.layers.merge.Add at 0x20c123d6b00>,\n",
       " <keras.layers.core.Activation at 0x20c12470ac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12429b00>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12490908>,\n",
       " <keras.layers.core.Activation at 0x20c124af860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c124c6e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c1256af28>,\n",
       " <keras.layers.core.Activation at 0x20c1256a048>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12620860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12640470>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12640d30>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12718518>,\n",
       " <keras.layers.merge.Add at 0x20c126b2550>,\n",
       " <keras.layers.core.Activation at 0x20c12738780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c127adcc0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c127f7080>,\n",
       " <keras.layers.core.Activation at 0x20c127185c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c1282a048>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c128cedd8>,\n",
       " <keras.layers.core.Activation at 0x20c128ce0b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12902320>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12983898>,\n",
       " <keras.layers.merge.Add at 0x20c129a8668>,\n",
       " <keras.layers.core.Activation at 0x20c129c6f28>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c129c6ef0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12a814a8>,\n",
       " <keras.layers.core.Activation at 0x20c12a81cf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12ad3cc0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12af1c88>,\n",
       " <keras.layers.core.Activation at 0x20c12b5beb8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12becfd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12c37828>,\n",
       " <keras.layers.merge.Add at 0x20c12c37d68>,\n",
       " <keras.layers.core.Activation at 0x20c12c86940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12c14cc0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12d11a58>,\n",
       " <keras.layers.core.Activation at 0x20c12d11978>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12d7cf28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12de90b8>,\n",
       " <keras.layers.core.Activation at 0x20c12d5fb38>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12e59fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12e3b048>,\n",
       " <keras.layers.merge.Add at 0x20c12ea49b0>,\n",
       " <keras.layers.core.Activation at 0x20c12f13978>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c12ed9f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12f7d198>,\n",
       " <keras.layers.core.Activation at 0x20c12f9c6d8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c1300be80>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c12fec2b0>,\n",
       " <keras.layers.core.Activation at 0x20c13053748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c131095f8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c1312a438>,\n",
       " <keras.layers.merge.Add at 0x20c1312ab70>,\n",
       " <keras.layers.core.Activation at 0x20c131e6438>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c131a3e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c13206908>,\n",
       " <keras.layers.core.Activation at 0x20c13223278>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c132c1438>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c132e2f98>,\n",
       " <keras.layers.core.Activation at 0x20c132e29b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c13316940>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c14389e10>,\n",
       " <keras.layers.merge.Add at 0x20c14389710>,\n",
       " <keras.layers.core.Activation at 0x20c143c0128>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c143c0e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c14465668>,\n",
       " <keras.layers.core.Activation at 0x20c14465ef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c1451fa20>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c1453cbe0>,\n",
       " <keras.layers.core.Activation at 0x20c1453cb38>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c14573eb8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c14616a58>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c14616240>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c14667f60>,\n",
       " <keras.layers.merge.Add at 0x20c146d0390>,\n",
       " <keras.layers.core.Activation at 0x20c1478d8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c14745978>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c147ac7b8>,\n",
       " <keras.layers.core.Activation at 0x20c147cb710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c1483bfd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c1481c780>,\n",
       " <keras.layers.core.Activation at 0x20c14885828>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c14913e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c148f7eb8>,\n",
       " <keras.layers.merge.Add at 0x20c1495b6a0>,\n",
       " <keras.layers.core.Activation at 0x20c149d50b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c149949b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c14a36a90>,\n",
       " <keras.layers.core.Activation at 0x20c14a57400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c14aeb550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c14b0dba8>,\n",
       " <keras.layers.core.Activation at 0x20c14aad518>,\n",
       " <keras.layers.convolutional.Conv2D at 0x20c14bc8390>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x20c14beaef0>,\n",
       " <keras.layers.merge.Add at 0x20c14bea908>,\n",
       " <keras.layers.core.Activation at 0x20c14c1efd0>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x20c14c1e630>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, training the ResNet part is not required, we have to train our dense output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Compiling our model using the **adam** optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bucka\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1\n",
      "301/301 [==============================] - 8266s 27s/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 7.3358e-04 - val_accuracy: 0.9060\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
